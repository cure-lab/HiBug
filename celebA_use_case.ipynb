{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images, predictions, labels\n",
    "\"\"\"\n",
    "Here is an example use case of our system.\n",
    "To use this example, ou need to get celebA dataset first. At http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
    "\n",
    "all_datas: a list of image address\n",
    "labels: a list of labels\n",
    "predictions: a list of predictions\n",
    "split: a list of tags, tag can be {TRAIN, VALID, UNLABELED}\n",
    "The above four list should have equal length\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from utils.defines import *\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "f = open(\"exampleData/celeba/list_attr_celeba.txt\")\n",
    "lines = list(f.readlines())\n",
    "lines = [line.strip('\\n').split(' ')[0] for line in lines]\n",
    "all_datas = ['../img_align_celeba/' + line for line in lines][1:]\n",
    "train_idx = np.load(\"exampleData/celebA/train_idx.npy\")[:80000]\n",
    "valid_idx = np.arange(len(all_datas))[-100000:-80000]\n",
    "unlabel_idx = np.arange(len(all_datas))[-80000:]\n",
    "print(len(all_datas), len(train_idx), len(valid_idx), len(unlabel_idx))\n",
    "idxs = np.concatenate([train_idx, valid_idx, unlabel_idx], axis=0)\n",
    "labels = np.load(\"exampleData/celebA/labels.npy\")[idxs]\n",
    "predictions = np.load(\"exampleData/celebA/predictions.npy\")[idxs]\n",
    "all_datas = [all_datas[i] for i in idxs]\n",
    "split = [TRAIN for i in  train_idx] + [VALID for i in  valid_idx] + [UNLABELED for i in  unlabel_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with our AI assistant, get visual attributes\n",
    "# Alternatively, you can propose the visual attributes by yourself. Then skip this step.\n",
    "from utils.gpt import ChatBot\n",
    "api_key = \"\" # Your GPT api key\n",
    "ChatBot = ChatBot(api_key)\n",
    "ChatBot.chat() # chat with our AI assistent, you can stop when you satisfied with the attributes in the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a corpus\n",
    "We provide an example of corpus in exampleData/celebA/corpus.json, you can skip this step\n",
    "\"\"\"\n",
    "from utils.gpt import get_des_question, get_binary_question,get_des_prompt, get_type\n",
    "from processData.Corpus import emptyAttribute\n",
    "import json\n",
    "attributes = ChatBot.attributes # a list of attributes: [\"attribute1\", \"attribute2\", \"attribute3\"]\n",
    "attribute_dict = {}\n",
    "main_object = \"human\"\n",
    "for name in attributes:\n",
    "    attribute_dict[name] = emptyAttribute()\n",
    "    data_type = get_type(main_object,name)\n",
    "    attribute_dict[name]['type'] = data_type\n",
    "    if data_type == 'binary':\n",
    "        attribute_dict[name]['question'] = get_binary_question(main_object,name)\n",
    "    else:\n",
    "        attribute_dict[name]['question'] = get_des_question(main_object,name)\n",
    "        attribute_dict[name]['prompt'] = [get_des_prompt(main_object,name),]\n",
    "\n",
    "# Although GPT is amazing, it is better to double-check the corpus base\n",
    "for key, content in attribute_dict.items():\n",
    "    print(key, content)\n",
    "\n",
    "f = open(\"exampleData/celebA/corpus.json\" ,'w')\n",
    "f.write(json.dumps(attribute_dict,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we can assign the value under each attribute for every data\n",
    "We provide an example of attribute values in exampleData/celebA/attribute.json, you can skip this step\n",
    "\"\"\"\n",
    "from processData.AttributeSelection import AttributeSelection\n",
    "AS = AttributeSelection(all_datas, labels, corpus_path=\"exampleData/celebA/corpus.json\")\n",
    "AS.match_description_to_data()\n",
    "AS.save_attributes(\"exampleData/celeba/attribute.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Diagnose the model based on 1. attributes, 2. label, 3. predictions\n",
    "\"\"\"\n",
    "# # Diagnose\n",
    "from processData.Diagnose import ModelDiagnose\n",
    "MD = ModelDiagnose(labels, predictions, split, \"exampleData/celeba/attribute.json\")\n",
    "MD.detect_failure_by_label()\n",
    "MD.detect_prediction_correlation()\n",
    "MD.detect_failure_prediction_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UI interface, explore the distribution of data, attributes\n",
    "Download the dataset before use it\n",
    "\"\"\"\n",
    "embeddings = np.load(\"exampleData/celebA/2Dfeatures.npy\")\n",
    "embeddings = embeddings[idxs]\n",
    "from interaction.interaction import Interaction\n",
    "interaction = Interaction(\n",
    "   datas=all_datas,\n",
    "   labels=labels,\n",
    "   predictions=predictions,\n",
    "   embeddings=embeddings,\n",
    "   tags=split,\n",
    "   attributes_dict_path=\"exampleData/celebA/attribute.json\"\n",
    ")\n",
    "interaction.interaction()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ae4531026500f286a4a1a9e0b6ec972ee541dc0213b77102b9dc9412992b0b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('scinet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
